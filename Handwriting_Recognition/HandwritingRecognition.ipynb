{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Handwriting Recognition"
      ],
      "metadata": {
        "id": "1uLbjSs-EM90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is used for handwriting recognition. It is based on a corresponding model on Kaggle and has been adapted and optimized for the specific example."
      ],
      "metadata": {
        "id": "dBCfLJAyENAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.utils import to_categorical, Sequence\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "from itertools import groupby\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "metadata": {
        "id": "4hHP4iZ3EIYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text document and use the text document to generate the path for the model\n",
        "file_path=\"../input/iam-handwriting-word-database/words_new.txt\"\n",
        "with open(file_path) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "label_raw=lines[18:]\n",
        "\n",
        "image_texts =[]\n",
        "image_paths =[]\n",
        "default_path=\"../input/iam-handwriting-word-database/iam_words/words/\"\n",
        "for label in label_raw:\n",
        "  if label.split()[1]==\"ok\":\n",
        "    image_texts.append(label.split()[-1])\n",
        "    image_paths.append(default_path+label.split()[0].split(\"-\")[0]+\"/\"+label.split()[0].split(\"-\")[0]+\"-\"+label.split()[0].split(\"-\")[1]+\"/\"+label.split()[0]+\".png\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:24:30.641605Z",
          "iopub.execute_input": "2022-06-20T22:24:30.641954Z",
          "iopub.status.idle": "2022-06-20T22:24:30.920706Z",
          "shell.execute_reply.started": "2022-06-20T22:24:30.641912Z",
          "shell.execute_reply": "2022-06-20T22:24:30.919874Z"
        },
        "trusted": true,
        "id": "czBmapd2EAr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define variables\n",
        "image_texts=image_texts\n",
        "image_paths=image_paths"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:24:30.922185Z",
          "iopub.execute_input": "2022-06-20T22:24:30.922502Z",
          "iopub.status.idle": "2022-06-20T22:24:30.927424Z",
          "shell.execute_reply.started": "2022-06-20T22:24:30.922475Z",
          "shell.execute_reply": "2022-06-20T22:24:30.925265Z"
        },
        "trusted": true,
        "id": "Y1q9c41LEAr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get paths of corrupt images\n",
        "corrupt_images = []\n",
        "\n",
        "for path in image_paths:\n",
        "    try:\n",
        "        img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2GRAY)\n",
        "    except:\n",
        "        corrupt_images.append(path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:24:33.378645Z",
          "iopub.execute_input": "2022-06-20T22:24:33.379114Z",
          "iopub.status.idle": "2022-06-20T22:31:59.206943Z",
          "shell.execute_reply.started": "2022-06-20T22:24:33.379071Z",
          "shell.execute_reply": "2022-06-20T22:31:59.206054Z"
        },
        "trusted": true,
        "id": "rMC4dFVYEAr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check corrupt images\n",
        "corrupt_images, len(corrupt_images)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:31:59.208961Z",
          "iopub.execute_input": "2022-06-20T22:31:59.209526Z",
          "iopub.status.idle": "2022-06-20T22:31:59.217671Z",
          "shell.execute_reply.started": "2022-06-20T22:31:59.209488Z",
          "shell.execute_reply": "2022-06-20T22:31:59.216625Z"
        },
        "trusted": true,
        "id": "YNDLIHVBEAr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete corrupt images\n",
        "for path in corrupt_images:\n",
        "\n",
        "    corrupt_index = image_paths.index(path)\n",
        "    del image_paths[corrupt_index]\n",
        "    del image_texts[corrupt_index]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:31:59.219726Z",
          "iopub.execute_input": "2022-06-20T22:31:59.220092Z",
          "iopub.status.idle": "2022-06-20T22:31:59.226053Z",
          "shell.execute_reply.started": "2022-06-20T22:31:59.220060Z",
          "shell.execute_reply": "2022-06-20T22:31:59.225251Z"
        },
        "trusted": true,
        "id": "IJ2GPBMMEAr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get vocabulary for the current dataset\n",
        "vocab_full = set(\"\".join(map(str, image_texts)))\n",
        "print(sorted(vocab_full))\n",
        "len(vocab_full)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:37:00.347766Z",
          "iopub.execute_input": "2022-06-20T22:37:00.348128Z",
          "iopub.status.idle": "2022-06-20T22:37:00.365083Z",
          "shell.execute_reply.started": "2022-06-20T22:37:00.348098Z",
          "shell.execute_reply": "2022-06-20T22:37:00.364013Z"
        },
        "trusted": true,
        "id": "VewG93ymEAr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete upper case letter to make vocabulary smaller\n",
        "vocab = []\n",
        "\n",
        "for letter in vocab_full:\n",
        "    # convert to lower case\n",
        "    let_low = letter.lower()\n",
        "    if let_low not in vocab:\n",
        "        vocab.append(let_low)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "print(len(vocab))\n",
        "vocab"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:37:02.441808Z",
          "iopub.execute_input": "2022-06-20T22:37:02.442170Z",
          "iopub.status.idle": "2022-06-20T22:37:02.450143Z",
          "shell.execute_reply.started": "2022-06-20T22:37:02.442138Z",
          "shell.execute_reply": "2022-06-20T22:37:02.449197Z"
        },
        "trusted": true,
        "id": "tp0d8AodEAr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get maximal lenght of words\n",
        "max_label_len = max([len(str(text)) for text in image_texts])\n",
        "max_label_len"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:37:06.173373Z",
          "iopub.execute_input": "2022-06-20T22:37:06.173698Z",
          "iopub.status.idle": "2022-06-20T22:37:06.187833Z",
          "shell.execute_reply.started": "2022-06-20T22:37:06.173668Z",
          "shell.execute_reply": "2022-06-20T22:37:06.186916Z"
        },
        "trusted": true,
        "id": "xNt2GJhFEAr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sorting vocabulary\n",
        "char_list = sorted(vocab)\n",
        "\n",
        "# define label encoding\n",
        "def encode_to_labels(txt):\n",
        "    # encoding each output word into digits\n",
        "    dig_lst = []\n",
        "\n",
        "    for index, char in enumerate(txt):\n",
        "        try:\n",
        "            dig_lst.append(char_list.index(char.lower()))\n",
        "        except:\n",
        "            print(char)\n",
        "\n",
        "    return pad_sequences([dig_lst], maxlen=max_label_len, padding='post', value=len(char_list))[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:41:24.138153Z",
          "iopub.execute_input": "2022-06-20T22:41:24.138471Z",
          "iopub.status.idle": "2022-06-20T22:41:24.146185Z",
          "shell.execute_reply.started": "2022-06-20T22:41:24.138436Z",
          "shell.execute_reply": "2022-06-20T22:41:24.145327Z"
        },
        "trusted": true,
        "id": "bV6hkFvCEAr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save padded labels\n",
        "padded_image_texts = list(map(encode_to_labels, image_texts))\n",
        "padded_image_texts[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T22:39:00.354322Z",
          "iopub.execute_input": "2022-06-20T22:39:00.354651Z",
          "iopub.status.idle": "2022-06-20T22:39:01.506560Z",
          "shell.execute_reply.started": "2022-06-20T22:39:00.354620Z",
          "shell.execute_reply": "2022-06-20T22:39:01.505777Z"
        },
        "trusted": true,
        "id": "16h-_OOREAr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into train, validation and test data\n",
        "train_image_paths = image_paths[ : int(len(image_paths) * 0.80)]\n",
        "train_image_texts = padded_image_texts[ : int(len(image_texts) * 0.80)]\n",
        "\n",
        "test_image_paths = image_paths[int(len(image_paths) * 0.80) : ]\n",
        "test_image_texts = padded_image_texts[int(len(image_texts) * 0.80) : ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:54:05.338171Z",
          "iopub.execute_input": "2022-06-20T18:54:05.338576Z",
          "iopub.status.idle": "2022-06-20T18:54:05.344915Z",
          "shell.execute_reply.started": "2022-06-20T18:54:05.338544Z",
          "shell.execute_reply": "2022-06-20T18:54:05.344063Z"
        },
        "trusted": true,
        "id": "DbZdZkzfEAr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define image preprocessing\n",
        "def process_single_sample(img_path, label):\n",
        "\n",
        "    # 1. Read image\n",
        "    img = tf.io.read_file(img_path)\n",
        "\n",
        "    # 2. Decode and convert to grayscale\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "\n",
        "    # 3. Data augmentation\n",
        "    img = tf.image.random_flip_left_right(img, seed=None)\n",
        "    img = tf.image.random_flip_up_down(img, seed=None)\n",
        "\n",
        "    # 4. Convert to float32 in [0, 1] range\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    # 5. Resize to the desired size\n",
        "    img = tf.image.resize(img, [32, 128])\n",
        "\n",
        "#     img = tf.transpose(img, perm=[1, 0, 2])\n",
        "    return {\"image\": img, \"label\": label}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:54:41.328388Z",
          "iopub.execute_input": "2022-06-20T18:54:41.328711Z",
          "iopub.status.idle": "2022-06-20T18:54:41.336759Z",
          "shell.execute_reply.started": "2022-06-20T18:54:41.328680Z",
          "shell.execute_reply": "2022-06-20T18:54:41.333600Z"
        },
        "trusted": true,
        "id": "siiTJqFLEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define batch size\n",
        "batch_size = 20\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_image_texts))\n",
        "#train_dataset = train_datagen.flow_from_directory(train_image_paths,classes=train_image_texts,batch_size=batch_size)\n",
        "\n",
        "# training dataset\n",
        "train_dataset = (\n",
        "    train_dataset.map(\n",
        "\n",
        "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# validation dataset\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_image_texts))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(\n",
        "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:54:43.127091Z",
          "iopub.execute_input": "2022-06-20T18:54:43.127428Z",
          "iopub.status.idle": "2022-06-20T18:54:44.490685Z",
          "shell.execute_reply.started": "2022-06-20T18:54:43.127398Z",
          "shell.execute_reply": "2022-06-20T18:54:44.489872Z"
        },
        "trusted": true,
        "id": "XspLAFGVEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping characters to integers\n",
        "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=char_list, num_oov_indices=0, mask_token=None\n",
        ")\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "train_data_fig, ax = plt.subplots(4, 4, figsize=(15, 10))\n",
        "train_data_fig.suptitle('Training data', weight='bold', size=18)\n",
        "\n",
        "# show some images and labels\n",
        "for batch in train_dataset.take(1):\n",
        "    images = batch[\"image\"]\n",
        "    labels = batch[\"label\"]\n",
        "    #print(labels)\n",
        "\n",
        "    for i in range(16):\n",
        "        img = (images[i] * 255).numpy().astype(\"uint8\")\n",
        "        label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode(\"utf-8\")\n",
        "\n",
        "        label = label.replace('[UNK]', '')\n",
        "        ax[i // 4, i % 4].imshow(img[:, :, 0], cmap=\"gray\")\n",
        "        ax[i // 4, i % 4].set_title(label)\n",
        "        ax[i // 4, i % 4].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:54:47.373927Z",
          "iopub.execute_input": "2022-06-20T18:54:47.374375Z",
          "iopub.status.idle": "2022-06-20T18:54:48.200343Z",
          "shell.execute_reply.started": "2022-06-20T18:54:47.374338Z",
          "shell.execute_reply": "2022-06-20T18:54:48.198664Z"
        },
        "trusted": true,
        "id": "zDajcqfQEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define CTC layer\n",
        "class CTCLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, name=None):\n",
        "\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions\n",
        "        return y_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:54:55.093820Z",
          "iopub.execute_input": "2022-06-20T18:54:55.094176Z",
          "iopub.status.idle": "2022-06-20T18:54:55.101347Z",
          "shell.execute_reply.started": "2022-06-20T18:54:55.094145Z",
          "shell.execute_reply": "2022-06-20T18:54:55.100479Z"
        },
        "trusted": true,
        "id": "35ri5-z2EAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define decoder for predictions\n",
        "def ctc_decoder(predictions):\n",
        "\n",
        "    #input: given batch of predictions from text rec model\n",
        "    #output: return lists of raw extracted text\n",
        "\n",
        "    text_list = []\n",
        "\n",
        "    pred_indcies = np.argmax(predictions, axis=2)\n",
        "\n",
        "    for i in range(pred_indcies.shape[0]):\n",
        "        ans = \"\"\n",
        "\n",
        "        ## merge repeats\n",
        "        merged_list = [k for k,_ in groupby(pred_indcies[i])]\n",
        "\n",
        "        ## remove blanks\n",
        "        for p in merged_list:\n",
        "            if p != len(char_list):\n",
        "                ans += char_list[int(p)]\n",
        "\n",
        "        text_list.append(ans)\n",
        "\n",
        "    return text_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:54:58.506487Z",
          "iopub.execute_input": "2022-06-20T18:54:58.506811Z",
          "iopub.status.idle": "2022-06-20T18:54:58.513140Z",
          "shell.execute_reply.started": "2022-06-20T18:54:58.506780Z",
          "shell.execute_reply": "2022-06-20T18:54:58.512182Z"
        },
        "trusted": true,
        "id": "6neKRq6BEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figures_list = []\n",
        "\n",
        "class PlotPredictions(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, frequency=1):\n",
        "        self.frequency = frequency\n",
        "        super(PlotPredictions, self).__init__()\n",
        "\n",
        "        batch = validation_dataset.take(1)\n",
        "        self.batch_images = list(batch.as_numpy_iterator())[0][\"image\"]\n",
        "        self.batch_labels = list(batch.as_numpy_iterator())[0][\"label\"]\n",
        "\n",
        "    def plot_predictions(self, epoch):\n",
        "\n",
        "        prediction_model = keras.models.Model(\n",
        "            self.model.get_layer(name=\"image\").input,\n",
        "            self.model.get_layer(name=\"dense\").output\n",
        "        )\n",
        "\n",
        "        preds = prediction_model.predict(self.batch_images)\n",
        "        pred_texts = ctc_decoder(preds)\n",
        "\n",
        "        orig_texts = []\n",
        "\n",
        "        for label in self.batch_labels:\n",
        "            orig_texts.append(\"\".join([char_list[int(char_ind)] for char_ind in label if not(char_ind == len(char_list))]))\n",
        "\n",
        "        fig , ax = plt.subplots(4, 4, figsize=(15, 5))\n",
        "        fig.suptitle('Epoch: '+str(epoch), weight='bold', size=14)\n",
        "\n",
        "        for i in range(16):\n",
        "\n",
        "            img = (self.batch_images[i, :, :, 0] * 255).astype(np.uint8)\n",
        "            title = f\"Prediction: {pred_texts[i]}\"\n",
        "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
        "            ax[i // 4, i % 4].set_title(title)\n",
        "            ax[i // 4, i % 4].axis(\"off\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        figures_list.append(fig)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % self.frequency == 0:\n",
        "            self.plot_predictions(epoch)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:55:01.183354Z",
          "iopub.execute_input": "2022-06-20T18:55:01.183762Z",
          "iopub.status.idle": "2022-06-20T18:55:01.196503Z",
          "shell.execute_reply.started": "2022-06-20T18:55:01.183728Z",
          "shell.execute_reply": "2022-06-20T18:55:01.195509Z"
        },
        "trusted": true,
        "id": "abAgzosJEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "epochs = 50\n",
        "\n",
        "# input with shape of height=32 and width=128\n",
        "inputs = Input(shape=(32, 128, 1), name=\"image\")\n",
        "\n",
        "labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
        "\n",
        "conv_1 = Conv2D(32, (3,3), activation = \"selu\", padding='same')(inputs)\n",
        "pool_1 = MaxPool2D(pool_size=(2, 2))(conv_1)\n",
        "\n",
        "conv_2 = Conv2D(64, (3,3), activation = \"selu\", padding='same')(pool_1)\n",
        "pool_2 = MaxPool2D(pool_size=(2, 2))(conv_2)\n",
        "\n",
        "conv_3 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(pool_2)\n",
        "conv_4 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(conv_3)\n",
        "\n",
        "conv_5 = Conv2D(512, (3,3), activation = \"selu\", padding='same')(conv_4)\n",
        "conv_6 = Conv2D(512, (3,3), activation = \"selu\", padding='same')(conv_5)\n",
        "drop_out=tf.keras.layers.Dropout(0.2)(conv_6)\n",
        "conv_7 = Conv2D(512, (3,3), activation = \"selu\", padding='same')(drop_out)\n",
        "conv_8 = Conv2D(512, (3,3), activation = \"selu\", padding='same')(conv_7)\n",
        "\n",
        "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_8)\n",
        "\n",
        "conv_5 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(pool_4)\n",
        "\n",
        "# Batch normalization layer\n",
        "batch_norm_5 = BatchNormalization()(conv_5)\n",
        "conv_6 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(batch_norm_5)\n",
        "batch_norm_6 = BatchNormalization()(conv_6)\n",
        "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        "conv_7 = Conv2D(64, (2,2), activation = \"selu\")(pool_6)\n",
        "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        "\n",
        "# bidirectional LSTM layers with units=128\n",
        "blstm_1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(squeezed)\n",
        "blstm_2 = Bidirectional(CuDNNLSTM(512, return_sequences=True))(blstm_1)\n",
        "blstm_3 = Bidirectional(CuDNNLSTM(512, return_sequences=True))(blstm_2)\n",
        "blstm_4 = Bidirectional(CuDNNLSTM(512, return_sequences=True))(blstm_3)\n",
        "blstm_5 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(blstm_4)\n",
        "dense2=Dense(128,activation = 'relu')(blstm_5)\n",
        "softmax_output = Dense(len(char_list) + 1, activation = 'softmax', name=\"dense\")(dense2)\n",
        "\n",
        "output = CTCLayer(name=\"ctc_loss\",)(labels, softmax_output)\n",
        "\n",
        "\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
        "\n",
        "#model to be used at training time\n",
        "model = Model(inputs=[inputs, labels], outputs=output)\n",
        "model.compile(loss = \"SparseCategoricalCrossentropy\", optimizer = optimizer,metrics=[tf.keras.metrics.Accuracy()])\n",
        "#model.compile(optimizer = optimizer, metrics = [])\n",
        "\n",
        "print(model.summary())\n",
        "file_path = \"/xxx/xxx/C_LSTM_best_cs.hdf5\"\n",
        "\n",
        "# save best model according to val_loss\n",
        "checkpoint = ModelCheckpoint(filepath=file_path,\n",
        "                                monitor='val_loss',\n",
        "                                verbose=1,\n",
        "                                save_best_only=True,\n",
        "                                mode='min')\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                        epochs = epochs,\n",
        "                        validation_data=validation_dataset,\n",
        "                        verbose = 1,\n",
        "                        shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T18:56:11.800507Z",
          "iopub.execute_input": "2022-06-20T18:56:11.800855Z",
          "iopub.status.idle": "2022-06-20T20:36:27.369315Z",
          "shell.execute_reply.started": "2022-06-20T18:56:11.800823Z",
          "shell.execute_reply": "2022-06-20T20:36:27.368277Z"
        },
        "trusted": true,
        "id": "tfUS8oIxEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save(\"/xxx/xxx/C_LSTM_best_c1.hdf5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-20T21:58:48.547469Z",
          "iopub.execute_input": "2022-06-20T21:58:48.547832Z",
          "iopub.status.idle": "2022-06-20T21:58:48.615693Z",
          "shell.execute_reply.started": "2022-06-20T21:58:48.547757Z",
          "shell.execute_reply": "2022-06-20T21:58:48.614411Z"
        },
        "trusted": true,
        "id": "pmvUpcVIEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "RLT6vQ9iEAr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the prediction model by extracting layers till the output layer\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense\").output\n",
        ")\n",
        "prediction_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "wcOv44RNEAr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Let's check results on some test samples\n",
        "for batch in validation_dataset.take(1):\n",
        "\n",
        "    batch_images = batch[\"image\"]\n",
        "    batch_labels = batch[\"label\"]\n",
        "\n",
        "    preds = prediction_model.predict(batch_images)\n",
        "    pred_texts = ctc_decoder(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        label = label.replace('[UNK]', '')\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    fig , ax = plt.subplots(4, 4, figsize=(15, 5))\n",
        "    for i in range(16):\n",
        "\n",
        "        img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)\n",
        "        title = f\"Prediction: {pred_texts[i]} / Original: {orig_texts[i]} \"\n",
        "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
        "        ax[i // 4, i % 4].set_title(title)\n",
        "        ax[i // 4, i % 4].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pGaFDCPeEAr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction validation dataset\n",
        "pred_texts_val = []\n",
        "orig_texts_val = []\n",
        "for batch in validation_dataset:\n",
        "\n",
        "    batch_images = batch[\"image\"]\n",
        "    batch_labels = batch[\"label\"]\n",
        "\n",
        "    preds = prediction_model.predict(batch_images)\n",
        "    pred_texts = ctc_decoder(preds)\n",
        "    for pred in pred_texts:\n",
        "        pred_texts_val.append(pred)\n",
        "\n",
        "\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        label = label.replace('[UNK]', '')\n",
        "        orig_texts_val.append(label)\n",
        "    #print(orig_texts)\n",
        "print(len(pred_texts_val))\n",
        "print(len(orig_texts_val))"
      ],
      "metadata": {
        "trusted": true,
        "id": "zghBR55qEAr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate prediction accuracy with bleu score\n",
        "score_val = corpus_bleu(orig_texts_test, pred_texts_test)\n",
        "print(score_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WtoZOp7zEAr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('BLEU-1: %f' % corpus_bleu(orig_texts_val, pred_texts_val, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(orig_texts_val, pred_texts_val, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(orig_texts_val, pred_texts_val, weights=(0.3, 0.3, 0.3, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(orig_texts_val, pred_texts_val, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "oJVs3OEiEAr6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}